{"nbformat_minor": 2, "cells": [{"execution_count": 1, "cell_type": "code", "source": "spark", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Starting Spark application\n"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>0</td><td>application_1517936636274_0004</td><td>spark</td><td>idle</td><td><a target=\"_blank\" href=\"http://hn1-bluewa.iaal3oxriwbu5a1bbgkwozvafc.bx.internal.cloudapp.net:8088/proxy/application_1517936636274_0004/\">Link</a></td><td><a target=\"_blank\" href=\"http://10.0.0.13:30060/node/containerlogs/container_1517936636274_0004_01_000001/livy\">Link</a></td><td>\u2714</td></tr></table>"}, "metadata": {}}, {"output_type": "stream", "name": "stdout", "text": "SparkSession available as 'spark'.\nres1: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@2665722c"}], "metadata": {"collapsed": false}}, {"execution_count": 9, "cell_type": "code", "source": "%%sql\nDROP TABLE airports", "outputs": [{"output_type": "display_data", "data": {"application/vnd.jupyter.widget-view+json": {"model_id": "f0d469d99f2e4190b443d749254d1455"}}, "metadata": {}}], "metadata": {"collapsed": false}}, {"execution_count": 10, "cell_type": "code", "source": "%%sql\nCREATE EXTERNAL TABLE airports (iata string, airport string, city string, state string, country string, llat string, llong string)\nROW FORMAT DELIMITED\nFIELDS TERMINATED BY ','\nLOCATION '/HdiSamples/Demo'\nTBLPROPERTIES (\"hive.input.dir.recursive\" = \"TRUE\", \n    \"hive.mapred.supports.subdirectories\" = \"TRUE\",\n    \"hive.supports.subdirectories\" = \"TRUE\", \n    \"mapred.input.dir.recursive\" = \"TRUE\")", "outputs": [{"output_type": "display_data", "data": {"application/vnd.jupyter.widget-view+json": {"model_id": "f99525f45df243c8bf2bf68a9b7a7685"}}, "metadata": {}}], "metadata": {"collapsed": false}}, {"execution_count": 39, "cell_type": "code", "source": "%%sql\nDROP TABLE airports_partitioned_hive", "outputs": [{"output_type": "display_data", "data": {"application/vnd.jupyter.widget-view+json": {"model_id": "e559f78d853946b4ad998e7ab0dc835d"}}, "metadata": {}}], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "%%sql\nDROP TABLE airports_partitioned_hive", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 81, "cell_type": "code", "source": "%%sh\ncat /Demo2", "outputs": [{"output_type": "stream", "name": "stderr", "text": "cat: /Demo2: No such file or directory\n"}], "metadata": {"collapsed": false}}, {"execution_count": 49, "cell_type": "code", "source": "%%sql\nCREATE EXTERNAL TABLE airports_partitioned_hive (iata string, airport string, city string, state string, llat string, llong string)\nPARTITIONED BY (country string)\nSTORED AS PARQUET\nLOCATION '/Demo2'\nTBLPROPERTIES (\"hive.input.dir.recursive\" = \"TRUE\", \n    \"hive.mapred.supports.subdirectories\" = \"TRUE\",\n    \"hive.supports.subdirectories\" = \"TRUE\", \n    \"mapred.input.dir.recursive\" = \"TRUE\")", "outputs": [{"output_type": "display_data", "data": {"application/vnd.jupyter.widget-view+json": {"model_id": "bbb41e2c841744c0ac592628e0bef71f"}}, "metadata": {}}], "metadata": {"collapsed": false}}, {"execution_count": 50, "cell_type": "code", "source": "%%sql\nALTER TABLE airports_partitioned_hive RECOVER PARTITIONS", "outputs": [{"output_type": "display_data", "data": {"application/vnd.jupyter.widget-view+json": {"model_id": "caed45459997416c8aee29e8a8902bf1"}}, "metadata": {}}], "metadata": {"collapsed": false}}, {"execution_count": 44, "cell_type": "code", "source": "val df = spark.sql (\"SELECT iata, airport, city, state, regexp_replace(country, '\\\"', '') AS country, llat, llong FROM airports\")", "outputs": [{"output_type": "stream", "name": "stdout", "text": "df: org.apache.spark.sql.DataFrame = [iata: string, airport: string ... 5 more fields]"}], "metadata": {"collapsed": false}}, {"execution_count": 79, "cell_type": "code", "source": "df.count()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "res98: Long = 3377"}], "metadata": {"collapsed": false}}, {"execution_count": 47, "cell_type": "code", "source": "df.write.partitionBy(\"country\").mode(\"overwrite\").format(\"parquet\").option(\"path\", \"/Demo2\").saveAsTable(\"Airports_Partitioned\")", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 48, "cell_type": "code", "source": "spark.sql(\"SELECT * FROM Airports_Partitioned\").count()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "res50: Long = 3377"}], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "import org.apache.spark.sql.hive._\n\nval hc = new HiveContext(spark.sparkContext)", "outputs": [], "metadata": {"scrolled": true, "collapsed": false}}, {"execution_count": 77, "cell_type": "code", "source": "%%sql\nALTER TABLE airports_partitioned_hive DROP PARTITION (country='USA')", "outputs": [{"output_type": "display_data", "data": {"application/vnd.jupyter.widget-view+json": {"model_id": "781d2f63e0a24c62b7047c25d56c954b"}}, "metadata": {}}], "metadata": {"collapsed": false}}, {"execution_count": 78, "cell_type": "code", "source": "%%sql\nALTER TABLE airports_partitioned_hive ADD PARTITION (country='USA') LOCATION '/Demo2/country=USA'", "outputs": [{"output_type": "display_data", "data": {"application/vnd.jupyter.widget-view+json": {"model_id": "0dadcf349a98434084e8b977ad38f4ed"}}, "metadata": {}}], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "hc.sql(\"SELECT * FROM Airports_Partitioned\").count()", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 72, "cell_type": "code", "source": "<!-- Returns 3377 misses subdirectory -->\nspark.sql (\"SELECT * FROM airports_partitioned_hive WHERE country='USA'\").count()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "res85: Long = 3363"}], "metadata": {"collapsed": false}}, {"execution_count": 76, "cell_type": "code", "source": "import org.apache.spark.sql.hive._\n\nval hc = new HiveContext(spark.sparkContext)\n\n<!-- Returns 3377 misses subdirectory -->\nhc.sql (\"SELECT * FROM airports_partitioned_hive\").count()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "res95: Long = 14"}], "metadata": {"collapsed": false}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Spark", "name": "sparkkernel", "language": ""}, "language_info": {"mimetype": "text/x-scala", "pygments_lexer": "scala", "name": "scala", "codemirror_mode": "text/x-scala"}}}